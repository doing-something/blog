---
title: '[WIP] Switching from GPT to YOLO for Faster Object Detection'
date: 2025-09-07
description: '사진 속 물건 인식 속도가 느려 YOLO를 도입하기로 한 과정과 배운 점을 기록합니다.'
draft: false
---

사진 속 물건을 인식하고 종류와 개수를 알려주는 기능을 구현하고 있다.  
처음에는 단순히 OpenAI GPT-4o-mini만 사용해서 이미지 분석을 맡겼는데, 만족스러운 답을 주는 대신 처리 속도가 너무 느린 문제가 있었다.

예를 들어 사용자가 사진을 올리면:

1. 이미지 업로드
2. WebP로 변환해 사이즈 축소 (전처리)
3. OpenAI GPT-4o-mini로 이미지 분석  
   → 구조화된 JSON 데이터로 반환

결과 품질은 좋았지만, 사진 속 물건이 많을수록 5~10초 이상 걸리는 속도 문제를 해결해야 했다.

---

## 문제를 해결하기 위한 고민

처음에는 OpenAI API에서 몇 가지 시도를 해봤다:

- 해상도 줄이기 → 전처리에서 512px 이하로 축소 → 효과 미미
- 출력 토큰 제한 → 응답은 빨라졌지만 분석 자체 속도는 그대로
- 모델 변경 → GPT-4o → GPT-4o-mini로 바꾸어도 큰 차이 없음

결국 GPT에게 이미지 해석부터 텍스트 생성까지 모두 맡기는 방식에 한계가 있다는 걸 깨달았다.

---

## YOLO를 도입하기로 한 이유

> "사진 속 물체를 찾고 개수를 세는 건, 전용 모델이 훨씬 빠르다."

그래서 떠올린 게 바로 YOLO(You Only Look Once).  
YOLO는 객체 탐지(Object Detection)에 특화된 딥러닝 모델이다.

### 용도별 모델 찾는 방법

1. **LLM에게 질문하기** - "이미지에서 물체를 빠르게 찾는 모델이 뭐가 있어?"
2. **Hugging Face Hub** - "huggingface.co"에서 태스크별 모델 검색
3. **Papers with Code** - 논문과 함께 구현체를 찾을 수 있는 사이트
4. **GitHub 검색** - "object detection", "image classification" 등 키워드로 검색
5. **ML 커뮤니티** - Reddit r/MachineLearning, Stack Overflow 등

- 물체의 위치와 라벨을 빠르게 찾아준다.
- 구조화된 JSON 형태로 상세한 정보를 받을 수 있다.
- 오픈소스라 비용이 없고 서버에 직접 배포 가능하다.
- 작은 물체나 다량 객체 인식에서 GPT보다 훨씬 강력하다.

---

## 새로운 아키텍처 설계

기존 방식에서는 GPT가 모든 걸 처리했지만, 이제는 역할을 분리하기로 했다.

```plaintext
[사용자]
   ↓ (사진 업로드)
[homekeeper-api/images]
   ↓
[YOLO Service] → 물체 탐지 (0.3초)
   ↓
[GPT Service] → JSON 구조 변환 (1-2초)
   ↓
[프론트엔드] → 기존 DetectedItem 구조로 표시
```

---

## 구현 계획

### 1. YOLO 서비스 통합

현재 `homekeeper-api` 프로젝트에 YOLO 서비스를 통합하는 구조:

```
homekeeper-api/
├── app/
│   ├── services/
│   │   ├── ai_vision.py      # 기존 GPT 서비스
│   │   └── yolo_service.py   # 새 YOLO 서비스
│   └── routers/
│       └── images.py         # 통합된 이미지 분석 API
├── yolo-service/             # YOLO 전용 디렉토리
│   ├── Dockerfile
│   ├── main.py
│   └── models/
└── docker-compose.yml        # YOLO 서비스 추가
```

- YOLOv8 모델을 별도 서비스로 분리하되 같은 프로젝트 내에서 관리
- 하이브리드 파이프라인: YOLO → GPT 순차 처리
- GPU 서버 사용시 0.3초 이내 응답 예상

### 2. 하이브리드 파이프라인 구현

- `/images/analyze` 엔드포인트에서 YOLO + GPT 하이브리드 처리
- 1단계: YOLO 서비스로 빠른 물체 탐지 (0.3초)
- 2단계: GPT 서비스로 YOLO 결과를 현재 JSON 구조로 변환 (1-2초)
- 결과: 기존 DetectedItem 구조 그대로 유지
- 전체 처리 시간: 1.3~2.3초로 단축 (기존 5~10초에서 개선)

반환할 JSON 구조:

```json
{
  "items": [
    {
      "name": "머그컵",
      "category": "주방용품",
      "subcategory": "컵/잔",
      "quantity": 1,
      "confidence": 0.9
    }
  ]
}
```

### 3. 예상 성능 개선

| 항목           | 기존 (GPT만)     | 개선 후 (YOLO + 구조화) |
| -------------- | ---------------- | ----------------------- |
| 평균 응답 시간 | 5~10초           | 1~2초 (목표)            |
| 비용           | API 호출당 $0.02 | YOLO 무료 + 서버 비용   |
| 정확도         | 85%              | 90%+ (목표)             |
| 데이터 구조    | 텍스트           | 구조화된 JSON           |

---

## 기대 효과

1. 도구는 적재적소에 - GPT가 만능은 아니다. 특화된 모델이 더 효율적일 때가 있다.
2. 하이브리드 파이프라인의 장점 - YOLO의 빠른 탐지 + GPT의 정확한 구조화를 결합한다.
3. 오픈소스 활용 - YOLO 같은 검증된 오픈소스를 활용하면 비용과 성능을 모두 잡을 수 있다.
4. 기존 구조 유지 - DetectedItem 구조를 그대로 유지하여 프론트엔드 변경 없이 성능만 개선한다.

이 계획을 프로젝트에 적용한 후, 실제 구현 결과와 성능 개선 사항에 대해 추가로 정리할 예정이다.
